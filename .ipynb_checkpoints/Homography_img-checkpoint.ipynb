{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 569521,
     "status": "ok",
     "timestamp": 1615800103851,
     "user": {
      "displayName": "SHRUTHEESH R",
      "photoUrl": "",
      "userId": "00894520623679044885"
     },
     "user_tz": -330
    },
    "id": "gpu4wsnSWNjx"
   },
   "outputs": [],
   "source": [
    "# %%writefile /content/Vis_Odometry/vis_odom_utils.py\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def umeyama_alignment(x, y, with_scale=True):\n",
    "    \"\"\"\n",
    "    Computes the least squares solution parameters of an Sim(m) matrix\n",
    "    that minimizes the distance between a set of registered points.\n",
    "    Umeyama, Shinji: Least-squares estimation of transformation parameters\n",
    "                     between two point patterns. IEEE PAMI, 1991\n",
    "    :param x: mxn matrix of points, m = dimension, n = nr. of data points\n",
    "    :param y: mxn matrix of points, m = dimension, n = nr. of data points\n",
    "    :param with_scale: set to True to align also the scale (default: 1.0 scale)\n",
    "    :return: r, t, c - rotation matrix, translation vector and scale factor\n",
    "    \"\"\"\n",
    "    if x.shape != y.shape:\n",
    "        assert False, \"x.shape not equal to y.shape\"\n",
    "\n",
    "    # m = dimension, n = nr. of data points\n",
    "    m, n = x.shape\n",
    "\n",
    "    # means, eq. 34 and 35\n",
    "    mean_x = x.mean(axis=1)\n",
    "    mean_y = y.mean(axis=1)\n",
    "\n",
    "    # variance, eq. 36\n",
    "    # \"transpose\" for column subtraction\n",
    "    sigma_x = 1.0 / n * (np.linalg.norm(x - mean_x[:, np.newaxis])**2)\n",
    "\n",
    "    # covariance matrix, eq. 38\n",
    "    outer_sum = np.zeros((m, m))\n",
    "    for i in range(n):\n",
    "        outer_sum += np.outer((y[:, i] - mean_y), (x[:, i] - mean_x))\n",
    "    cov_xy = np.multiply(1.0 / n, outer_sum)\n",
    "\n",
    "    # SVD (text betw. eq. 38 and 39)\n",
    "    u, d, v = np.linalg.svd(cov_xy)\n",
    "\n",
    "    # S matrix, eq. 43\n",
    "    s = np.eye(m)\n",
    "    if np.linalg.det(u) * np.linalg.det(v) < 0.0:\n",
    "        # Ensure a RHS coordinate system (Kabsch algorithm).\n",
    "        s[m - 1, m - 1] = -1\n",
    "\n",
    "    # rotation, eq. 40\n",
    "    r = u.dot(s).dot(v)\n",
    "\n",
    "    # scale & translation, eq. 42 and 41\n",
    "    c = 1 / sigma_x * np.trace(np.diag(d).dot(s)) if with_scale else 1.0\n",
    "    t = mean_y - np.multiply(c, r.dot(mean_x))\n",
    "\n",
    "    return r, t, c\n",
    "\n",
    "\n",
    "def unprojection_kp(kp, kp_depth, cam_intrinsics):\n",
    "    \"\"\"Convert kp to XYZ\n",
    "    Args:\n",
    "        kp (Nx2 array): [x, y] keypoints\n",
    "        kp_depth (Nx2 array): keypoint depth\n",
    "        cam_intrinsics (Intrinsics): camera intrinsics\n",
    "    Returns:\n",
    "        XYZ (Nx3): 3D coordinates\n",
    "    \"\"\"\n",
    "    N = kp.shape[0]\n",
    "    # initialize regular grid\n",
    "    XYZ = np.ones((N, 3, 1))\n",
    "    XYZ[:, :2, 0] = kp\n",
    "    \n",
    "    inv_K = np.ones((1, 3, 3))\n",
    "    inv_K[0] = np.linalg.inv(cam_intrinsics)\n",
    "    inv_K = np.repeat(inv_K, N, axis=0)\n",
    "\n",
    "    XYZ = np.matmul(inv_K, XYZ)[:, :, 0]\n",
    "    XYZ[:, 0] = XYZ[:, 0] * kp_depth\n",
    "    XYZ[:, 1] = XYZ[:, 1] * kp_depth\n",
    "    XYZ[:, 2] = XYZ[:, 2] * kp_depth\n",
    "    return XYZ\n",
    "\n",
    "def normalize_kp(kp, cam_intr):\n",
    "    kp_norm = kp.copy()\n",
    "    kp_norm[:, 0] = \\\n",
    "        (kp[:, 0] - cam_intr[0,2]) / cam_intr[0,0]\n",
    "    kp_norm[:, 1] = \\\n",
    "        (kp[:, 1] - cam_intr[1,2]) / cam_intr[1,1]\n",
    "\n",
    "    kp1_3D = np.ones((3, kp_norm.shape[0]))\n",
    "    kp1_3D[0], kp1_3D[1] = kp_norm[:, 0].copy(), kp_norm[:, 1].copy()\n",
    "\n",
    "    return kp1_3D\n",
    "\n",
    "def triangulation(kp1, kp2, T_1w, T_2w, cam_intr):\n",
    "    \"\"\"Triangulation to get 3D points\n",
    "    Args:\n",
    "        kp1 (Nx2): keypoint in view 1 (normalized)\n",
    "        kp2 (Nx2): keypoints in view 2 (normalized)\n",
    "        T_1w (4x4): pose of view 1 w.r.t  i.e. T_1w (from w to 1)\n",
    "        T_2w (4x4): pose of view 2 w.r.t world, i.e. T_2w (from w to 2)\n",
    "    Returns:\n",
    "        X (3xN): 3D coordinates of the keypoints w.r.t world coordinate\n",
    "        X1 (3xN): 3D coordinates of the keypoints w.r.t view1 coordinate\n",
    "        X2 (3xN): 3D coordinates of the keypoints w.r.t view2 coordinate\n",
    "    \"\"\"\n",
    "    \n",
    "    kp1_norm = kp1.copy()\n",
    "    kp2_norm = kp2.copy()\n",
    "\n",
    "    kp1_norm[:, 0] = \\\n",
    "        (kp1[:, 0] - cam_intr[0,2]) / cam_intr[0,0]\n",
    "    kp1_norm[:, 1] = \\\n",
    "        (kp1[:, 1] - cam_intr[1,2]) / cam_intr[1,1]\n",
    "    kp2_norm[:, 0] = \\\n",
    "        (kp2[:, 0] - cam_intr[0,2]) / cam_intr[0,0]\n",
    "    kp2_norm[:, 1] = \\\n",
    "        (kp2[:, 1] - cam_intr[1,2]) / cam_intr[1,1]\n",
    "\n",
    "    kp1_3D = np.ones((3, kp1_norm.shape[0]))\n",
    "    kp2_3D = np.ones((3, kp2_norm.shape[0]))\n",
    "    kp1_3D[0], kp1_3D[1] = kp1_norm[:, 0].copy(), kp1_norm[:, 1].copy()\n",
    "    kp2_3D[0], kp2_3D[1] = kp2_norm[:, 0].copy(), kp2_norm[:, 1].copy()\n",
    "\n",
    "    X = cv2.triangulatePoints(T_1w[:3], T_2w[:3], kp1_3D[:2], kp2_3D[:2])\n",
    "    X /= X[3]\n",
    "    X1 = T_1w[:3] @ X\n",
    "    X2 = T_2w[:3] @ X\n",
    "    return X[:3].T, X1, X2\n",
    "\n",
    "\n",
    "def transform_points(points_3D, pose):\n",
    "  points_4D = np.c_[ points_3D,  np.ones(len(points_3D)) ].T\n",
    "  transformed_points_4D = pose @ points_4D\n",
    "  points_3D = transformed_points_4D[:3].T\n",
    "  return points_3D\n",
    "\n",
    "\n",
    "\n",
    "def find_scale(f13D, f23D):\n",
    "\n",
    "    valid_1 = f13D[...,2] > 0\n",
    "    valid_2 = f23D[...,2] > 0\n",
    "    valid = valid_1 & valid_2\n",
    "    f13D = f13D[valid]\n",
    "    f23D = f23D[valid]\n",
    "    indices = np.random.choice(np.arange(0,len(f23D)), size=(5 * len(f23D),2),replace=True)\n",
    "    indices = indices[indices[...,0]!=indices[...,1]]\n",
    "    num = np.linalg.norm(f13D[indices[...,0]] - f13D[indices[...,1]], axis=1).reshape((len(indices),1))\n",
    "    den = np.linalg.norm(f23D[indices[...,0]] - f23D[indices[...,1]], axis=1).reshape((len(indices),1))\n",
    "    ransac = linear_model.RANSACRegressor(\n",
    "                base_estimator=linear_model.LinearRegression(\n",
    "                    fit_intercept=False),\n",
    "                min_samples=2,\n",
    "                max_trials=100,\n",
    "                stop_probability=0.99,\n",
    "                residual_threshold=1.0\n",
    "                                        )\n",
    "    ransac.fit(\n",
    "            num,\n",
    "            den\n",
    "            )\n",
    "    \n",
    "    scale = ransac.estimator_.coef_[0, 0]\n",
    "    return scale\n",
    "    return np.median(den/num)\n",
    "\n",
    "def find_scale_depthonly(real_depth, unscaled_depth):\n",
    "\n",
    "    valid_1 = real_depth > 0\n",
    "    valid_2 = unscaled_depth > 0\n",
    "    valid = valid_1 & valid_2\n",
    "    real_depth = real_depth[valid]\n",
    "    unscaled_depth = unscaled_depth[valid]\n",
    "\n",
    "    # residuals = \n",
    "\n",
    "    # Estimate scale (ransac)\n",
    "    if valid.sum() > 0: #self.cfg.translation_scale.ransac.min_samples:\n",
    "        # RANSAC scaling solver\n",
    "        ransac = linear_model.RANSACRegressor(\n",
    "                    base_estimator=linear_model.LinearRegression(\n",
    "                        fit_intercept=False),\n",
    "                    min_samples=3,\n",
    "                    max_trials=100,\n",
    "                    stop_probability=0.99,\n",
    "                    residual_threshold=1\n",
    "                    )\n",
    "        ransac.fit(\n",
    "                f13D.reshape(-1, 1),\n",
    "                f23D.reshape(-1, 1)\n",
    "                )\n",
    "        scale = ransac.estimator_.coef_[0, 0]\n",
    "    else:\n",
    "        scale = -1\n",
    "\n",
    "    return scale\n",
    "\n",
    "# Taken from  DF-VO : https://github.com/Huangying-Zhan/DF-VO\n",
    "import numpy as np\n",
    "class SE3():\n",
    "    \"\"\"SE3 object consists rotation and translation components\n",
    "    Attributes:\n",
    "        pose (4x4 numpy array): camera pose\n",
    "        inv_pose (4x4 numpy array): inverse camera pose\n",
    "        R (3x3 numpy array): Rotation component\n",
    "        t (3x1 numpy array): translation component,\n",
    "    \"\"\"\n",
    "    def __init__(self, np_arr=None):\n",
    "        if np_arr is None:\n",
    "            self._pose = np.eye(4)\n",
    "        else:\n",
    "            self._pose = np_arr\n",
    "\n",
    "    @property\n",
    "    def pose(self):\n",
    "        \"\"\" pose (4x4 numpy array): camera pose \"\"\"\n",
    "        return self._pose\n",
    "\n",
    "    @pose.setter\n",
    "    def pose(self, value):\n",
    "        self._pose = value\n",
    "\n",
    "    @property\n",
    "    def inv_pose(self):\n",
    "        \"\"\" inv_pose (4x4 numpy array): inverse camera pose \"\"\"\n",
    "        return np.linalg.inv(self._pose)\n",
    "\n",
    "    @inv_pose.setter\n",
    "    def inv_pose(self, value):\n",
    "        self._pose = np.linalg.inv(value)\n",
    "\n",
    "    @property\n",
    "    def R(self):\n",
    "        return self._pose[:3, :3]\n",
    "\n",
    "    @R.setter\n",
    "    def R(self, value):\n",
    "        self._pose[:3, :3] = value\n",
    "\n",
    "    @property\n",
    "    def t(self):\n",
    "        return self._pose[:3, 3:]\n",
    "\n",
    "    @t.setter\n",
    "    def t(self, value):\n",
    "        self._pose[:3, 3:] = value\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "# from sim3 import SE3\n",
    "class FramePair:\n",
    "    def __init__(self, f1, f2, matches_no, left_kp, right_kp, frame1_idx = None,  cheirality_pts_ct=0, inlier_pts_ct=0, pose=SE3()):\n",
    "        self.frame1 = f1\n",
    "        self.frame2 = f2\n",
    "        self.left_kp = left_kp\n",
    "        self.right_kp = right_kp\n",
    "        self.cheirality_pts_ct = cheirality_pts_ct\n",
    "        self.inlier_pts_ct = inlier_pts_ct\n",
    "        self.pose = pose\n",
    "        self.avg_optical_flow = 0\n",
    "        self.matches_no = matches_no\n",
    "        self.ess_mat = None\n",
    "        self.frame_index = frame1_idx\n",
    "\n",
    "\n",
    "    def getpose(self):\n",
    "        # return self.pose\n",
    "        pos = SE3()\n",
    "        pos.t = self.pose.t.copy()\n",
    "        pos.R = self.pose.R.copy()\n",
    "        return pos\n",
    "\n",
    "    def getkeypts(self):\n",
    "        return (self.left_kp, self.right_kp)\n",
    "    \n",
    "    def getchecks(self):\n",
    "        return (self.cheirality_pts_ct, self.inlier_pts_ct)\n",
    "\n",
    "class Frame:\n",
    "    def __init__(self, id, img, kps, desc, fil, pose = SE3(), seg_img = None, depth = np.zeros(1), image_arr = None, ):\n",
    "        self.id = id\n",
    "        self.image = img\n",
    "        self.keypoints = kps\n",
    "        self.descriptors = desc\n",
    "        self.filename = fil\n",
    "        self.depth = depth\n",
    "        self.pose = pose\n",
    "        self.image_arr = image_arr\n",
    "        self.glob_pose = None\n",
    "        self.tracked_kps = None\n",
    "        self.global_pose = None\n",
    "        self.kps_index = np.arange(len(kps))\n",
    "        self.seg_img = seg_img\n",
    "\n",
    "    \n",
    "    def getitems(self):\n",
    "        return (self.image, self.keypoints, self.descriptors, self.filename)\n",
    "\n",
    "    def get_kp_desc(self):\n",
    "        return (self.keypoints, self.descriptors)\n",
    "\n",
    "    def get_image(self):\n",
    "        return self.image\n",
    "\n",
    "    def get_file(self):\n",
    "        return self.filename\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 606547,
     "status": "ok",
     "timestamp": 1615800140881,
     "user": {
      "displayName": "SHRUTHEESH R",
      "photoUrl": "",
      "userId": "00894520623679044885"
     },
     "user_tz": -330
    },
    "id": "rYImspYoWPRp"
   },
   "outputs": [],
   "source": [
    "# %%writefile /content/homography_computation/auto_park_utils.py\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import cv2 \n",
    "from google.colab.patches import cv2_imshow\n",
    "from PIL import Image\n",
    "import numpy as np \n",
    "import glob\n",
    "import sys\n",
    "sys.path.insert(1, 'ShelfNet18_realtime/')\n",
    "from evaluate import MscEval\n",
    "from shelfnet import ShelfNet\n",
    "\n",
    "class auto_park_vision():\n",
    "    def __init__(self,weights_path):\n",
    "\n",
    "        self.n_classes = 19\n",
    "        self.eval_define() #Define Object of class MscEval\n",
    "\n",
    "    def forward_pass(self,frame=None,img_path=None):\n",
    "\n",
    "        if(img_path != None):\n",
    "            img = Image.open(img_path)\n",
    "        else:\n",
    "            img = frame \n",
    "        orig_img = np.array(img)\n",
    "        # orig_img = cv2.imread(img_path)\n",
    "        # cv2_imshow(img)\n",
    "        #Preprocess Image\n",
    "        to_tensor = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "            ])\n",
    "        img = to_tensor(img)\n",
    "        \n",
    "\n",
    "        _, H, W = img.shape\n",
    "        # print(\"H,W:\",H,W)\n",
    "        #Change image size to the form NCHW from CHW\n",
    "        img = img.unsqueeze(0)\n",
    "\n",
    "        probs = torch.zeros((1, self.n_classes, H, W))\n",
    "        probs.requires_grad = False\n",
    "        img = img.cuda()        \n",
    "\n",
    "        # for sc in self.scales:\n",
    "        prob = self.evaluator.scale_crop_eval(img, scale=1.0) #prob.type torch.cuda.FloatTensor\n",
    "        prob = prob.detach().cpu()\n",
    "        prob = prob.data.numpy()\n",
    "        preds = np.argmax(prob, axis=1) #preds.dtype int64\n",
    "\n",
    "        #Changed \n",
    "        preds = preds.squeeze().astype(np.uint8)\n",
    "        preds[preds == 0] = 255\n",
    "        preds = preds.astype(np.uint8)\n",
    "        return preds\n",
    "\n",
    "\n",
    "    def eval_define(self):\n",
    "\n",
    "        n_classes = self.n_classes\n",
    "        net = ShelfNet(n_classes=n_classes)\n",
    "\n",
    "        net.load_state_dict(torch.load(weights_path))\n",
    "        net.cuda()\n",
    "        net.eval()\n",
    "        self.evaluator = MscEval(net, dataloader=None, scales=[1.0],flip=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 606547,
     "status": "ok",
     "timestamp": 1615800140885,
     "user": {
      "displayName": "SHRUTHEESH R",
      "photoUrl": "",
      "userId": "00894520623679044885"
     },
     "user_tz": -330
    },
    "id": "d6i3YM5rWROY"
   },
   "outputs": [],
   "source": [
    "# %%writefile /content/homography_computation/main.py\n",
    "import glob\n",
    "import numpy as np\n",
    "import cv2 \n",
    "import os\n",
    "from google.colab.patches import cv2_imshow\n",
    "import time\n",
    "from statistics import mean\n",
    "import pickle\n",
    "\n",
    "def world_2d(points_ls):\n",
    "    '''\n",
    "    Convert a list of 3d points to corresponding image points using homography\n",
    "    '''\n",
    "    points_2d_ls = []\n",
    "    for point in points_ls:\n",
    "        point_3d = np.asarray(point)\n",
    "        point_3d = point_3d.reshape(3,1)\n",
    "        # print(\"point_3d\",point_3d)\n",
    "        point_2d = np.dot(H,point_3d)\n",
    "        point_2d = point_2d // point_2d[2,0]\n",
    "        points_2d_ls.append(point_2d)\n",
    "        # print(\"point_2d\",point_2d)\n",
    "    return points_2d_ls\n",
    "\n",
    "def project_points(img,points_2d_ls):\n",
    "    '''\n",
    "    Draw a bounding rectangle on the image using the computed homography\n",
    "    '''\n",
    "    # cv2_imshow(img)\n",
    "    # for point_2d in points_2d_ls:\n",
    "    #     cv2.circle(img,(point_2d[0],point_2d[1]), 5, (0,0,255), -1)\n",
    "        \n",
    "    #For visualization\n",
    "    N = len(points_2d_ls)\n",
    "    for i in range(0,N):\n",
    "        cv2.line(img,(points_2d_ls[i%N][0],points_2d_ls[i%N][1]),\\\n",
    "                 (points_2d_ls[(i+1)%N][0],points_2d_ls[(i+1)%N][1]),\\\n",
    "                 (0,0,255),4)\n",
    "    #Image with points drawn on it\n",
    "    cv2_imshow(img)\n",
    "\n",
    "def pot_parking_spot(orig_img,inf_img,points_2d_ls):\n",
    "    '''\n",
    "    Function to detect potential parking spot\n",
    "    '''\n",
    "    #TODO: Optimize the code\n",
    "    xcoords_ls = []\n",
    "    ycoords_ls = []\n",
    "    for point in points_2d_ls:\n",
    "        xcoords_ls.append(point[0][0])\n",
    "        ycoords_ls.append(point[1][0])\n",
    "    \n",
    "    #Line equations of the top and bottom line\n",
    "    coeff_top = np.polyfit(xcoords_ls[0:2],ycoords_ls[0:2],1)\n",
    "    line_top = np.poly1d(coeff_top)\n",
    "\n",
    "    coeff_bottom = np.polyfit(xcoords_ls[2:4],ycoords_ls[2:4],1)\n",
    "    line_bottom = np.poly1d(coeff_bottom)\n",
    "    # print(\"line_bottom\",line_bottom)\n",
    "    # print(\"line_top\",line_top)\n",
    "    flag_top = 0\n",
    "    flag_bottom = 0\n",
    "    #Points for potential parking spot\n",
    "    pt_tl = []\n",
    "    pt_tr = []\n",
    "    pt_bl = []\n",
    "    pt_br = []\n",
    "    for x in range(0,inf_img.shape[1]):\n",
    "        if(inf_img[int(line_top(x)),x] == 255 and flag_top == 0):\n",
    "            pt_tl = [int(line_top(x)),x]\n",
    "            pt_tr = [int(line_top(x+200)),int(x+200)]\n",
    "            # cv2.circle(orig_img,(pt_tl[1],pt_tl[0]), 5, (0,0,255), -1)\n",
    "            # cv2.circle(orig_img,(pt_tr[1],pt_tr[0]), 5, (0,0,255), -1)\n",
    "            # cv2_imshow(orig_img)\n",
    "            flag_top = 1\n",
    "\n",
    "        if(inf_img[int(line_bottom(x)),x] == 255 and flag_bottom == 0):\n",
    "            pt_bl = [int(line_bottom(x)),x]\n",
    "            pt_br = [int(line_bottom(x+200)),int(x+200)]\n",
    "            # cv2.circle(orig_img,(pt_bl[1],pt_bl[0]), 5, (0,0,255), -1)\n",
    "            # cv2.circle(orig_img,(pt_br[1],pt_br[0]), 5, (0,0,255), -1)\n",
    "            # cv2_imshow(orig_img)\n",
    "            flag_bottom = 1\n",
    "        \n",
    "        if(flag_top == 1 and flag_bottom ==1):\n",
    "            # cv2_imshow(orig_img)\n",
    "            break\n",
    "\n",
    "    if(flag_top == 1 and flag_bottom == 1):\n",
    "        cv2.line(orig_img,(pt_tl[1],pt_tl[0]),(pt_tr[1],pt_tr[0]),(0,0,255),2)\n",
    "        cv2.line(orig_img,(pt_tr[1],pt_tr[0]),(pt_br[1],pt_br[0]),(0,0,255),2)\n",
    "        cv2.line(orig_img,(pt_br[1],pt_br[0]),(pt_bl[1],pt_bl[0]),(0,0,255),2)\n",
    "        cv2.line(orig_img,(pt_bl[1],pt_bl[0]),(pt_tl[1],pt_tl[0]),(0,0,255),2)\n",
    "    \n",
    "    pt_ls = [pt_bl,pt_br,pt_tr,pt_tl]\n",
    "    return orig_img,pt_ls\n",
    "    \n",
    "    \n",
    "def chk_cnts(pt_ls):\n",
    "    '''\n",
    "    Check if contour pt_ls contains invalid entries\n",
    "    '''\n",
    "    for pt in pt_ls:\n",
    "        if not pt:\n",
    "            return False\n",
    "    \n",
    "    return True\n",
    "def ret_line_eq(pt1,pt2):\n",
    "    '''\n",
    "    Returns m1,c1 given 2 points\n",
    "    '''\n",
    "    points = [pt1,pt2]\n",
    "    x_coords, y_coords = zip(*points)\n",
    "    A = np.vstack([x_coords,np.ones(len(x_coords))]).T\n",
    "    m1, c1 = np.linalg.lstsq(A, y_coords)[0] #TODO: Improve this, it computes the least square solution\n",
    "    return m1,c1\n",
    "\n",
    "\n",
    "def find_midpoint(pt_ls):\n",
    "    '''\n",
    "    Find the midpoint given 4 corners of the contour\n",
    "    '''\n",
    "    m1,c1 = ret_line_eq(pt_ls[0],pt_ls[2])\n",
    "    m2,c2 = ret_line_eq(pt_ls[1],pt_ls[3])\n",
    "\n",
    "    #Solve the 2 eqns to obtain the midpoint\n",
    "    A = np.array([[-m1,1],\n",
    "                 [-m2,1]],dtype=np.float64)\n",
    "    B = np.array([c1,c2])\n",
    "    midpoint = np.linalg.inv(A).dot(B)\n",
    "    #Inverse homography matrix\n",
    "    inv_h = np.linalg.inv(H)\n",
    "    #Conversion from Numpy coordinates to OpenCV coordinates\n",
    "    #TODO: Optimize this computation\n",
    "    midpoint_homography = np.copy(midpoint).reshape(2,1)\n",
    "    midpoint_homography[0,0] = midpoint[1]\n",
    "    midpoint_homography[1,0] = midpoint[0]\n",
    "    midpoint_homography = np.append(midpoint_homography,1).reshape(-1,1)\n",
    "    # midpoint_homography.append(midpoint[0])\n",
    "    # midpoint_homography.append(1)\n",
    "    world_midpoint = np.dot(inv_h,midpoint_homography)\n",
    "    world_midpoint = world_midpoint / world_midpoint[2,0]\n",
    "    return world_midpoint , midpoint\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify Feature Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from R2D2 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VO Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 3900,
     "status": "ok",
     "timestamp": 1615802154011,
     "user": {
      "displayName": "SHRUTHEESH R",
      "photoUrl": "",
      "userId": "00894520623679044885"
     },
     "user_tz": -330
    },
    "id": "XeZsl9RaW3K_"
   },
   "outputs": [],
   "source": [
    "# Version - Shrutheesh\n",
    "\n",
    "\n",
    "# %%writefile /content/Vis_Odometry/main_cell.py\n",
    "# Parking Spot\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import copy\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import glob\n",
    "import re\n",
    "import shutil\n",
    "from sklearn import linear_model\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from google.colab.patches import cv2_imshow\n",
    "from scipy.spatial.transform import Rotation as sciPyR\n",
    "\n",
    "np.random.seed(4123)\n",
    "\n",
    "listlength = 1\n",
    "\n",
    "def multidim_intersect(arr1, arr2):\n",
    "    #DOUBT: Why are we performing arr1_view and arr2_view?\n",
    "    # arr1_view = arr1.view([('',arr1.dtype)]*arr1.shape[1])\n",
    "    # arr2_view = arr2.view([('',arr2.dtype)]*arr2.shape[1])\n",
    "    arr1 = arr1.cpu().numpy()\n",
    "    arr2 = arr2.cpu().numpy()\n",
    "    arr1_view = arr1.view([('',arr1.dtype)]*arr1.shape[1])\n",
    "    arr2_view = arr2.view([('',arr2.dtype)]*arr2.shape[1])\n",
    "    intersected, ind1, ind2= np.intersect1d(arr1_view, arr2_view, return_indices = True)\n",
    "    # print(\"intersected\",intersected)\n",
    "    # print(\"ind1\",ind1)\n",
    "    # print(\"ind2\",ind2)\n",
    "    return (intersected,ind1,ind2)\n",
    "    # return (intersected.view(arr1.dtype).reshape(-1, arr1.shape[1]), ind2)ind1,  \n",
    "\n",
    "def append_to_list(l, ele, listlen= listlength):\n",
    "    l.append(ele)\n",
    "    return l[-listlen:]\n",
    "\n",
    "class VisualOdometry:\n",
    "        def __init__(self, cam_intr, homo_matrix):\n",
    "\n",
    " \n",
    "                self.cam_intr = cam_intr.copy()            \n",
    "\n",
    "                H = homo_matrix.copy()\n",
    "                                                                                                     \n",
    "\n",
    "                self.homography_matrix = H.copy()\n",
    "\n",
    "                self.ref_data = []\n",
    "                self.global_poses = {0: SE3().pose}\n",
    "                self.global_pose = SE3()\n",
    "                self.pose_ctr = 0\n",
    "                self.cur_data = None\n",
    "                self.frame_pairs = []\n",
    "                self.viz = True\n",
    "                self.scale = 1\n",
    "                self.img_id = 0\n",
    "\n",
    "                self.no_matches = []\n",
    "                self.inlier_pts = []\n",
    "                self.cheirality_pts = []\n",
    "\n",
    "\n",
    "                self.ref_kps_index = None\n",
    "                self.ref_pose = SE3()\n",
    "                self.good_points_3D = None\n",
    "\n",
    "                # self.contour = np.array([[405,390],[615,350],[605,450],[385,480] ], dtype=np.int32)\n",
    "\n",
    "                self.initialized = False\n",
    "                self.pose_ctr = 0\n",
    "                \n",
    "\n",
    "                self.ref_len = 1\n",
    "                self.method = 'learned'\n",
    "\n",
    "                self.essentialMat = {'iter' : 3, 'thresh' : 0.3, 'prob' : 0.99}\n",
    "\n",
    "                if os.path.exists(self.method.lower()) == False:\n",
    "                        os.mkdir(self.method.lower())\n",
    "\n",
    "\n",
    "        def update_global_pose(self, poss):\n",
    "            self.global_pose.t += self.global_pose.R @ poss.t\n",
    "            self.global_pose.R = self.global_pose.R @ poss.R\n",
    "\n",
    "        def computepose_2D_2D(self,framepair):\n",
    "\n",
    "                # \n",
    "                best_inlier_cnt = 0\n",
    "                retval = False\n",
    "                pose = SE3()\n",
    "                left_kp, right_kp = framepair.getkeypts()\n",
    "\n",
    "                E1, inliers = cv2.findEssentialMat(right_kp.copy(), left_kp.copy(),\n",
    "                                                                                    self.cam_intr,\n",
    "                                                                                    method = cv2.RANSAC,\n",
    "                                                                                    prob = self.essentialMat['prob'], threshold = 5.0)\n",
    "\n",
    "                inliers = np.squeeze(inliers)\n",
    "                inliers_copy_og = inliers.copy()\n",
    "                pts, R1, t1, _ = cv2.recoverPose(E1, right_kp.copy(), left_kp.copy(), self.cam_intr, mask = inliers_copy_og.copy())\n",
    "\n",
    "                left_kp = left_kp.copy()[inliers_copy_og==1]\n",
    "                right_kp = right_kp.copy()[inliers_copy_og==1]\n",
    "                framepair.left_kp = left_kp.copy()\n",
    "                framepair.right_kp = right_kp.copy()\n",
    "                framepair.left_kp_og = left_kp.copy()\n",
    "                framepair.right_kp_og = right_kp.copy()\n",
    "\n",
    "                framepair.frame_index = framepair.frame_index[inliers_copy_og==1]\n",
    "\n",
    "                self.vizualize_custom_matches(framepair.frame1.image, framepair.frame2.image, left_kp, right_kp)\n",
    "                \n",
    "\n",
    "\n",
    "                avgoptflow = np.sum(np.linalg.norm(left_kp-right_kp, axis = 1))/len(right_kp)\n",
    "                if avgoptflow < 5:\n",
    "                #     print(\"NO PARALLAX\")\n",
    "                    return retval, framepair\n",
    "                \n",
    "                if pts > 70:\n",
    "                    pose.R = R1\n",
    "                    pose.t = t1\n",
    "                    retval = True\n",
    "                    framepair.pose = pose\n",
    "                else:\n",
    "                    retval = False\n",
    "                    return retval, framepair\n",
    "\n",
    "\n",
    "                for loopindex in range(self.essentialMat['iter']):\n",
    "\n",
    "                        \n",
    "                        new_list = np.random.randint(0, left_kp.shape[0], (left_kp.shape[0]))\n",
    "                        new_left_kp = left_kp.copy()[new_list]\n",
    "                        new_right_kp = right_kp.copy()[new_list]\n",
    "                        E, inliers = cv2.findEssentialMat(new_right_kp, new_left_kp,\n",
    "                                                                                            self.cam_intr,\n",
    "                                                                                            method = cv2.RANSAC,\n",
    "                                                                                            prob = self.essentialMat['prob'], threshold = self.essentialMat['thresh'])\n",
    "                        inliers = np.squeeze(inliers)\n",
    "                        inliers_copy = inliers.copy()\n",
    "                        left_kp_inliers = new_left_kp.copy()[inliers_copy==1]\n",
    "                        right_kp_inliers = new_right_kp.copy()[inliers_copy==1]\n",
    "                        avgoptflow = np.sum(np.linalg.norm(left_kp_inliers-right_kp_inliers, axis = 1))/len(left_kp_inliers)\n",
    "                        if avgoptflow < 5:\n",
    "                                # print(\"LESS THAN 5\")\n",
    "                                continue\n",
    "                        points, R_tmp, t_tmp, _ = cv2.recoverPose(E, new_right_kp, new_left_kp, self.cam_intr, mask = inliers_copy)\n",
    "\n",
    "                        #ADJUSTMENT STEP\n",
    "\n",
    "                        # t_tmp[1] = 0\n",
    "                        # t_tmp = t_tmp / np.linalg.norm\n",
    "\n",
    "                        if points < 50:\n",
    "                                print(\"LESS THAN 50\", points)\n",
    "                                continue\n",
    "                        \n",
    "                        if inliers.sum() > best_inlier_cnt and points>50:\n",
    "                                retval = True\n",
    "                                best_inlier_cnt = inliers.sum()\n",
    "                                \n",
    "                                pose.R = R_tmp\n",
    "                                pose.t = t_tmp\n",
    "                                \n",
    "                                framepair.cheirality_pts_ct = points\n",
    "                                framepair.inlier_pts_ct = best_inlier_cnt\n",
    "                                framepair.pose = pose\n",
    "                                framepair.ess_mat = E\n",
    "                                framepair.inl = inliers\n",
    "\n",
    "\n",
    "                return retval, framepair\n",
    "\n",
    "\n",
    "        def computepose_3D_2D(self,framepair):\n",
    "\n",
    "                # \n",
    "                best_inlier_cnt = 0\n",
    "                retval = False\n",
    "                pose = SE3()\n",
    "\n",
    "                left_kp, right_kp = framepair.getkeypts()\n",
    "\n",
    "                # self.vizualize_custom_matches(framepair.frame1.image, framepair.frame2.image, left_kp, right_kp, 'BEFORE ESSMAT')\n",
    "                # print(\"PNP BETWEEN \", framepair.frame1.filename, framepair.frame2.filename, len(left_kp))\n",
    "\n",
    "                E1, inliers = cv2.findEssentialMat(right_kp.copy(), left_kp.copy(),\n",
    "                                                                                    self.cam_intr,\n",
    "                                                                                    method = cv2.RANSAC,\n",
    "                                                                                    prob = self.essentialMat['prob'], threshold = 3.0)\n",
    "\n",
    "                inliers = np.squeeze(inliers)\n",
    "                inliers_copy_og = inliers.copy()\n",
    "\n",
    "\n",
    "                left_kp = left_kp.copy()[inliers_copy_og==1]\n",
    "                right_kp = right_kp.copy()[inliers_copy_og==1]\n",
    "                # print(len(left_kp), len(inliers_copy_og))\n",
    "                # print(framepair.frame_index)\n",
    "\n",
    "                # print(\"#################### ESS MAT INLIERS : \", len(left_kp), \" OUT OF \", len(inliers))\n",
    "                # self.vizualize_custom_matches(framepair.frame1.image, framepair.frame2.image, left_kp, right_kp, 'AFTER ESSMAT')\n",
    "\n",
    "                points_3D = self.good_points_3D[framepair.frame_index[..., 0]][inliers_copy_og==1]\n",
    "\n",
    "\n",
    "\n",
    "                framepair.left_kp = left_kp.copy()\n",
    "                framepair.right_kp = right_kp.copy()\n",
    "                framepair.left_kp_og = left_kp.copy()\n",
    "                framepair.right_kp_og = right_kp.copy()\n",
    "                framepair.frame_index = framepair.frame_index[inliers_copy_og==1]\n",
    "\n",
    "\n",
    "                avgoptflow = np.sum(np.linalg.norm(left_kp-right_kp, axis = 1))/len(right_kp)\n",
    "                if avgoptflow < 5 or len(left_kp) < 50:\n",
    "                #     print(\"NO PARALLAX\")\n",
    "                    return retval, framepair, 1000, 0\n",
    "                \n",
    "\n",
    "                # print(\"DOING PNP with %d points out of %d points between %s and %s\"%(len(i1), len(left_kp), framepair.frame1.filename, framepair.frame2.filename))\n",
    "                best_rt = []\n",
    "                best_inliers = None\n",
    "                best_inlier = 0\n",
    "                \n",
    "                # t1 = time.time()\n",
    "                for loopindex in range(self.essentialMat['iter']):\n",
    "                     \n",
    "                        new_list = np.random.randint(0, points_3D.shape[0], (points_3D.shape[0]))\n",
    "                        new_left_kp = left_kp.copy()[new_list]\n",
    "                        new_right_kp = right_kp.copy()[new_list]\n",
    "                        new_points_3D = points_3D.copy()[new_list]\n",
    "                        # print(\"$$$$$ PNP \", len(new_right_kp))\n",
    "                        # flag, r, t = cv2.solvePnP(objectPoints = new_points_3D, imagePoints = new_right_kp, cameraMatrix = self.cam_intr, distCoeffs = None, rvec = cv2.Rodrigues(R1_tmp)[0], tvec = t1_tmp, useExtrinsicGuess = True, flags = cv2.SOLVEPNP_ITERATIVE)\n",
    "                        # inlier = np.random.rand(60,2)\n",
    "                        # print(inlier.shape[0])\n",
    "                        flag, r, t, inlier = cv2.solvePnPRansac(objectPoints = new_points_3D, imagePoints = new_right_kp, cameraMatrix = self.cam_intr, distCoeffs = None, iterationsCount = 1000, reprojectionError=1.250)\n",
    "                        # flag, r, t, inlier = cv2.solvePnPRansac(objectPoints = new_points_3D, imagePoints = new_right_kp, cameraMatrix = self.cam_intr, distCoeffs = np.array([0.0427517,     0.20910611,    0.00161125,    0.00081772, -0.79102898]), iterationsCount = 1000, reprojectionError=1.75)\n",
    "                        # print(inlier.shape)\n",
    "\n",
    "                        if flag and inlier.shape[0] > best_inlier and inlier.shape[0] > 25:\n",
    "                                best_rt = [r, t]\n",
    "                                best_inlier = inlier.shape[0]\n",
    "                                best_inliers = np.squeeze(inlier).copy()\n",
    "\n",
    "                pose = SE3()\n",
    "                if len(best_rt) != 0:\n",
    "                        # print()\n",
    "                        retval = True\n",
    "                        r, t = best_rt\n",
    "                        pose.R = cv2.Rodrigues(r)[0]\n",
    "                        pose.t = t\n",
    "                        pose.pose = pose.inv_pose.copy()\n",
    "                        # print(pose.t.T)\n",
    "                        framepair.pose = pose\n",
    "                else:\n",
    "                    bad=True\n",
    "                #     print(\"NO IT IS A BAD PNP\")\n",
    "\n",
    "                return retval, framepair, len(left_kp), best_inlier\n",
    "\n",
    "\n",
    "\n",
    "        def vizualize_matches(self,framepair, imgidx, val):\n",
    "                cv_kp1 = [cv2.KeyPoint(x=pt[0], y=pt[1], _size=1) for pt in framepair.left_kp]\n",
    "                cv_kp2 = [cv2.KeyPoint(x=pt[0], y=pt[1], _size=1) for pt in framepair.right_kp]\n",
    "                dmtches = [cv2.DMatch(_imgIdx=0,_queryIdx=i, _trainIdx=i, _distance = 0) for i in range(len(cv_kp1))]\n",
    "                out_img = cv2.drawMatches(framepair.frame1.image, cv_kp1, framepair.frame2.image, cv_kp2, dmtches[::50], None, (0,255,255), -1, None, 2)\n",
    "                # cv2.imwrite('outfolder/%06d_match.jpg'%imgidx, out_img)\n",
    "                cv2.imshow('match', out_img)\n",
    "\n",
    "\n",
    "        def vizualize_custom_matches(self,img1, img2, kps1, kps2, name = 'match_inl'):\n",
    "                cv_kp1 = [cv2.KeyPoint(x=pt[0], y=pt[1], _size=1) for pt in kps1]\n",
    "                cv_kp2 = [cv2.KeyPoint(x=pt[0], y=pt[1], _size=1) for pt in kps2]\n",
    "                dmtches = [cv2.DMatch(_imgIdx=0,_queryIdx=i, _trainIdx=i, _distance = 0) for i in range(len(cv_kp1))]\n",
    "                out_img = cv2.drawMatches(img1, cv_kp1, img2, cv_kp2, dmtches[::5], None, (0,255,255), -1, None, 2)\n",
    "                cv2.imwrite('outfolder/%06d_match_inl.jpg'%self.img_id, out_img)\n",
    "                # cv2.imshow(name, out_img)\n",
    "                # cv2.waitKey(0)\n",
    "\n",
    "\n",
    "        def vizualize_kps(self,img1, img2, kps, val, to_update = False, draw_contour = False):\n",
    "\n",
    "\n",
    "              cv_kp1 = [cv2.KeyPoint(x=pt[0], y=pt[1], _size=5) for pt in kps]\n",
    "              if img1!=None:\n",
    "                out_img = cv2.drawKeypoints(img1.astype(np.uint8), cv_kp1, None, (0,255,255))\n",
    "                cv2_imshow(out_img)\n",
    "                cv2.imwrite('outfolder/%06d_d.jpg'%val, out_img)\n",
    "              # if img2 != None:\n",
    "              # out_img = cv2.drawKeypoints(img2.astype(np.uint8), cv_kp1, None, (0,255,255))\n",
    "              out_img = cv2.circle(img2.astype(np.uint8),(kps[0][0],kps[0][1]),10, (0, 255, 255),thickness=2, lineType=8, shift=0) \n",
    "              # cv2_imshow(out_img)\n",
    "              if draw_contour:\n",
    "                out_img = cv2.drawContours(out_img, [self.contours], 0, (0,255,0), 3)\n",
    "              # cv2_imshow(out_img)\n",
    "\n",
    "              # out_img = cv2.putText(out_img, \"Distance of midpoint from vehicle : \" + str(np.squeeze(transform_points(self.midpoint_3D, self.cur_data.pose.inv_pose))), (200,50), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,255), 2 )\n",
    "              # out_img = cv2.putText(out_img, \"Distance travelled by vehicle : \" + str(np.squeeze(self.cur_data.pose.t.T)), (200,80), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,255),2 )\n",
    "              cv2.imwrite('outfolder/t%s_c.jpg'%val, out_img)\n",
    "\n",
    "        def update_frames_data(self, framepair):\n",
    "                self.ref_data = append_to_list(self.ref_data, self.cur_data, 2)\n",
    "                self.good_points_3D = transform_points(self.good_points_3D, framepair.pose.inv_pose)\n",
    "        \n",
    "        def update_framepairs(self, fp):\n",
    "                self.frame_pairs = append_to_list(self.frame_pairs, fp, 4)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        def triangulate_new_ref_points(self, framepair):\n",
    "\n",
    "                ref_kp, ref_desc = framepair.frame1.get_kp_desc()\n",
    "                cur_kp, cur_desc = framepair.frame2.get_kp_desc()\n",
    "                matches = get_matches(ref_kp, ref_desc, cur_kp, cur_desc, framepair.frame1.image.shape)\n",
    "                left_kp = ref_kp[matches[:, 0], : 2].astype(np.float32)\n",
    "                right_kp = cur_kp[matches[:, 1], : 2].astype(np.float32)\n",
    "\n",
    "                diff = np.linalg.norm(left_kp- right_kp, axis=1)\n",
    "                diff_mask = diff > 5\n",
    "                matches = matches[diff_mask]\n",
    "                left_kp = left_kp[diff_mask]\n",
    "                right_kp = right_kp[diff_mask]\n",
    "                \n",
    "                E1, inliers = cv2.findEssentialMat(left_kp.copy(), right_kp.copy(),\n",
    "                                                   self.cam_intr, method = cv2.RANSAC,\n",
    "                                                   prob = self.essentialMat['prob'], threshold = 3.0)\n",
    "\n",
    "                \n",
    "                inliers = np.squeeze(inliers)\n",
    "                inliers_copy_og = inliers.copy()\n",
    "                left_kp = left_kp.copy()[inliers_copy_og==1]\n",
    "                right_kp = right_kp.copy()[inliers_copy_og==1]\n",
    "                matches = matches[inliers_copy_og==1]\n",
    "\n",
    "                # self.vizualize_custom_matches(framepair.frame1.image, framepair.frame2.image, left_kp, right_kp, \"triangulation\")\n",
    "\n",
    "                frame_3D_pts, _, _ = triangulation(left_kp, right_kp, np.eye(4), framepair.pose.inv_pose, self.cam_intr)\n",
    "                non_zero_mask_tri = frame_3D_pts[...,2] > 0\n",
    "\n",
    "                if len(non_zero_mask_tri[non_zero_mask_tri > 0]) > 50:\n",
    "                        self.ref_kps_index = matches[non_zero_mask_tri]\n",
    "                        self.good_points_3D = frame_3D_pts[non_zero_mask_tri]\n",
    "                # print(\"\\n -- %d points triangulated out of %d points --\"%(len(self.good_points_3D), len(frame_3D_pts)))\n",
    "                return len(non_zero_mask_tri[non_zero_mask_tri > 0])\n",
    "\n",
    "\n",
    "        def get_point_in_other_image(self, framepair, to_update = False):\n",
    "\n",
    "            temp_pose = framepair.frame2.pose.inv_pose\n",
    "            projectedpts = cv2.projectPoints(self.midpoint_3D, cv2.Rodrigues(temp_pose[:3, :3])[0], temp_pose[:3,3], self.cam_intr, None)[0]\n",
    "            self.vizualize_kps(None, self.cur_data.image, projectedpts[0].astype(np.int32), self.img_id, to_update)\n",
    "        #     cv2.waitKey(0)\n",
    "\n",
    "\n",
    "        def save_poses(self):\n",
    "                with open('r2d2parking.pkl', 'wb') as f: pickle.dump(self.global_poses, f)\n",
    "\n",
    "\n",
    "        def get_local_scale(self,framepair):\n",
    "                '''\n",
    "                Find out the global scale to update the 3D coordinates of the midpoint\n",
    "                '''\n",
    "                \n",
    "\n",
    "                seg_map = framepair.frame1.seg_img\n",
    "                H = self.homography_matrix.copy()\n",
    "                \n",
    "                H_inv = np.linalg.inv(H)\n",
    "\n",
    "\n",
    "                corresponding_2D_pts = framepair.frame1.keypoints[self.ref_kps_index[:, 0]].astype(np.int32)[..., :2]\n",
    "                seg_map_mask = seg_map[corresponding_2D_pts[..., 1], corresponding_2D_pts[..., 0]] == 255\n",
    "                # done\n",
    "                cnt_keypoints = corresponding_2D_pts[seg_map_mask]\n",
    "                \n",
    "                # print(cnt_keypoints)\n",
    "                cnt_keypoints_homo = np.c_[cnt_keypoints,np.ones(len(cnt_keypoints))]\n",
    "\n",
    "                good_road_points_3D = self.good_points_3D[seg_map_mask]\n",
    "                # print(good_road_points_3D.shape)\n",
    "\n",
    "\n",
    "                # Find 3D points\n",
    "                cnt_keypoints_3d = []\n",
    "                for pt in cnt_keypoints_homo:\n",
    "                        pt = pt.reshape((3,1))\n",
    "                        cnt_keypoints_3d.append(np.dot(H_inv,pt))\n",
    "                \n",
    "                \n",
    "                cnt_keypoints_3d = np.squeeze(np.asarray(cnt_keypoints_3d))\n",
    "                cnt_keypoints_3d_normalized = np.divide(cnt_keypoints_3d.T, abs(cnt_keypoints_3d[..., -1])).T\n",
    "\n",
    "                cnt_keypoints_depth = abs(cnt_keypoints_3d_normalized[..., 0] / 100)\n",
    "                cnt_keypoints_3d = unprojection_kp(cnt_keypoints, cnt_keypoints_depth, self.cam_intr)\n",
    "                cnt_depth_mask = cnt_keypoints_depth < 30\n",
    "                if len(cnt_keypoints_3d[cnt_depth_mask]) > 50:\n",
    "                        true_scale = find_scale(good_road_points_3D[cnt_depth_mask], cnt_keypoints_3d[cnt_depth_mask])\n",
    "                else:\n",
    "                        return 1\n",
    "\n",
    "\n",
    "                # cv2.waitKey(1)\n",
    "                return true_scale\n",
    "\n",
    "\n",
    "        def get_global_scale(self,framepair,midpoint):\n",
    "                '''\n",
    "                Find out the global scale to update the 3D coordinates of the midpoint\n",
    "                '''\n",
    "                \n",
    "\n",
    "                seg_map = framepair.frame1.seg_img\n",
    "                H = self.homography_matrix.copy()\n",
    "                # H[1,2] *= -1\n",
    "                \n",
    "                H_inv = np.linalg.inv(H)\n",
    "                # print(H)\n",
    "                # H_inv = np.linalg.inv(self.homography_matrix)\n",
    "                # print(self.good_points_3D.shape, self.ref_kps_index[:, 0].shape)\n",
    "                mid_pt_homo = np.asarray([midpoint[0], midpoint[1], 1]).reshape((3,1))\n",
    "                midpoint_3D = np.dot(H_inv,mid_pt_homo)\n",
    "                midpoint_3D_normalized = midpoint_3D / abs(midpoint_3D[-1])\n",
    "                # print(\"MIDPOINT 3D \" , midpoint_3D, midpoint,    midpoint_3D_normalized, framepair.pose.t.T, np.linalg.norm(framepair.pose.t.T))\n",
    "\n",
    "                depth = abs(midpoint_3D_normalized[0] / 100)\n",
    "\n",
    "                midpoint_3D = unprojection_kp(np.asarray([midpoint]), depth, self.cam_intr)\n",
    "                # print(midpoint_3D, midpoint_3D.shape)\n",
    "                # done\n",
    "\n",
    "\n",
    "                corresponding_2D_pts = framepair.frame1.keypoints[self.ref_kps_index[:, 0]].astype(np.int32)[..., :2]\n",
    "                seg_map_mask = seg_map[corresponding_2D_pts[..., 1], corresponding_2D_pts[..., 0]] == 255\n",
    "                # done\n",
    "                cnt_keypoints = corresponding_2D_pts[seg_map_mask]\n",
    "                \n",
    "                # print(cnt_keypoints)\n",
    "                cnt_keypoints_homo = np.c_[cnt_keypoints,np.ones(len(cnt_keypoints))]\n",
    "                # cnt_keypoints_homo[:,0] = cnt_keypoints[:,0]\n",
    "                # cnt_keypoints_homo[:,1] = cnt_keypoints[:,1]\n",
    "\n",
    "\n",
    "                good_road_points_3D = self.good_points_3D[seg_map_mask]\n",
    "                # print(good_road_points_3D.shape)\n",
    "\n",
    "\n",
    "                # Find 3D points\n",
    "                cnt_keypoints_3d = []\n",
    "                for pt in cnt_keypoints_homo:\n",
    "                        pt = pt.reshape((3,1))\n",
    "                        cnt_keypoints_3d.append(np.dot(H_inv,pt))\n",
    "                \n",
    "                \n",
    "                cnt_keypoints_3d = np.squeeze(np.asarray(cnt_keypoints_3d))\n",
    "                cnt_keypoints_3d_normalized = np.divide(cnt_keypoints_3d.T, abs(cnt_keypoints_3d[..., -1])).T\n",
    "\n",
    "                cnt_keypoints_depth = abs(cnt_keypoints_3d_normalized[..., 0] / 100)\n",
    "                cnt_keypoints_3d = unprojection_kp(cnt_keypoints, cnt_keypoints_depth, self.cam_intr)\n",
    "                cnt_depth_mask = cnt_keypoints_depth < 40\n",
    "                self.vizualize_kps(None, framepair.frame1.image,cnt_keypoints[cnt_depth_mask], 0 )\n",
    "                # print(cnt_keypoints_homo[::10], cnt_keypoints_3d[::10], cnt_keypoints_3d_normalized[::10])\n",
    "                # print(cnt_keypoints_3d.shape, good_road_points_3D.shape)\n",
    "                # if len(cnt_keypoints_3d[cnt_depth_mask]) > 50:\n",
    "\n",
    "                # print(\"MIDPOINT    \", midpoint_3D, len(cnt_keypoints_3d[cnt_depth_mask]))\n",
    "\n",
    "                if len(cnt_keypoints_3d[cnt_depth_mask]) > 30:\n",
    "                        true_scale = find_scale(good_road_points_3D[cnt_depth_mask], cnt_keypoints_3d[cnt_depth_mask])\n",
    "                else:\n",
    "                    print(\"LESS\")\n",
    "                    # print(cnt_keypoints_3d[cnt_depth_mask], len(cnt_keypoints_3d[cnt_depth_mask]))\n",
    "                    return -1\n",
    "\n",
    "                # true_scale = find_scale(good_road_points_3D[cnt_depth_mask], cnt_keypoints_3d[cnt_depth_mask])\n",
    "                # else:\n",
    "                        # return 1\n",
    "                # print(\"TRUE SCALE : \", true_scale)\n",
    "                # true_scale = find_scale_depth_only(good_road_points_3D[..., 2], cnt_keypoints_depth)\n",
    "\n",
    "\n",
    "                self.midpoint_3D = midpoint_3D.reshape((1,3))\n",
    "                self.midpoint_3D /= true_scale\n",
    "                # cv2.waitKey(1)\n",
    "                return true_scale\n",
    "\n",
    "\n",
    "        def process_frame(self, img, seg_img, midpoint, frame_no, imgfile):\n",
    "                '''\n",
    "                contours: Area within which keypoints are to be tracked\n",
    "                img: OpenCV image\n",
    "                midpoint: Midpoint to be tracked\n",
    "                frame_no: Frame number\n",
    "                '''\n",
    "                #NOTE:\n",
    "                #Use midpoint and contours for 2 frames i.e until we have established 2D-2D correspondencies\n",
    "                #Followed by this use pure Visual Odometry for servoing\n",
    "\n",
    "\n",
    "                \n",
    "\n",
    "                # fil = self.imgfiles[0]\n",
    "                #For the first frame\n",
    "                if(frame_no == 0): #First frame\n",
    "                        if self.method != 'OF':\n",
    "                                # img = cv2.imread(fil)\n",
    "                                #Converting OpenCV image into PIL format\n",
    "                                #Original Image: img\n",
    "                                kp, desc = extract_features_and_desc(img)                \n",
    "                                frame1 = Frame(id = 0, img = img, kps = kp, desc = desc, fil = imgfile, pose = SE3(), seg_img = seg_img)\n",
    "                                \n",
    "                        \n",
    "                        self.ref_data = append_to_list(self.ref_data, frame1)\n",
    "                        self.initialized = False\n",
    "                        self.parking_spot_points_found = False\n",
    "                \n",
    "                else: #NOTE: frame_no = imgidx\n",
    "                        cur_img = img\n",
    "                        imgidx = frame_no\n",
    "                        cur_fil = imgfile\n",
    "                        self.img_id = imgidx\n",
    "                                \n",
    "                        if self.method != 'OF':\n",
    "                                # cur_img = cv2.imread(cur_fil)\n",
    "                                # cur_kp, cur_desc = extract_features_and_desc(cur_img, cur_fil)\n",
    "                                cur_kp, cur_desc = extract_features_and_desc(cur_img)\n",
    "                                frame1 = self.ref_data[-1]\n",
    "                                ref_kp, ref_desc = self.ref_data[-1].get_kp_desc()\n",
    "                                # self.vizualize_kps(None,cur_img,cur_kp, 0 )\n",
    "                                frame2 = Frame(id = imgidx, img = cur_img, kps = cur_kp, desc = cur_desc, fil = cur_fil, pose = SE3(), seg_img = seg_img)\n",
    "                                self.cur_data = frame2\n",
    "                                # print(frame1.kps_index)\n",
    "                                matches = get_matches(ref_kp[frame1.kps_index], ref_desc[frame1.kps_index], cur_kp, cur_desc, cur_img.shape)\n",
    "                                try:\n",
    "                                        ref_keypoints = ref_kp[frame1.kps_index[matches[:, 0]], : 2].astype(np.float32)\n",
    "                                except Exception as e:\n",
    "                                        \n",
    "                                        print(e, matches.shape, frame1.kps_index.shape, ref_kp.shape)\n",
    "\n",
    "                                # ref_keypoints = ref_kp[matches[:, 0], : 2].astype(np.float32)\n",
    "                                cur_keypoints = cur_kp[matches[:, 1], : 2].astype(np.float32)\n",
    "                        \n",
    "                                framepair = FramePair(frame1, frame2, matches, ref_keypoints, cur_keypoints, matches)\n",
    "\n",
    "                        \n",
    "                        if self.initialized == False:\n",
    "                            retval, framepair = self.computepose_2D_2D(framepair)\n",
    "                        \n",
    "\n",
    "                        else:\n",
    "                            retval, framepair, common_pts, best_inliers = self.computepose_3D_2D(framepair)\n",
    "                            scale = np.linalg.norm(framepair.pose.t)\n",
    "                        \n",
    "\n",
    "\n",
    "                        # if self.img_id > 145:\n",
    "                        #     imdone\n",
    "\n",
    "                        to_update = False\n",
    "                        if retval==True:\n",
    "                                \n",
    "                                if self.initialized == False:\n",
    "                                        self.triangulate_new_ref_points(framepair)\n",
    "                                        global_scale = self.get_global_scale(framepair,midpoint)\n",
    "                                        # if global_scale < 0.70 or global_scale > 4.00:\n",
    "                                        if global_scale < 0.50 or global_scale > 4.00:\n",
    "                                                # self.get_point_in_other_image(framepair, to_update)\n",
    "                                            # print(\"************************VERY POOR*******************\", global_scale)\n",
    "                                            return \n",
    "                                        \n",
    "                                        framepair.frame1.kps_index = self.ref_kps_index[:, 0]\n",
    "                                        framepair.frame2.kps_index = self.ref_kps_index[:, 1]\n",
    "                                        \n",
    "                                        # print(\"FOUND ABSOLUTE SCALE : \", global_scale, framepair.frame1.filename, framepair.frame2.filename, self.midpoint_3D * global_scale)\n",
    "                                        scale = global_scale\n",
    "                                        self.global_scale = scale\n",
    "                                        # framepair.pose.t *= scale\n",
    "                                        # self.good_points_3D *= scale\n",
    "                                        common_pts = 250\n",
    "                                        best_inliers = 100                        \n",
    "                                        self.initialized=True\n",
    "                                        to_update = True\n",
    "                                \n",
    "\n",
    "                                # if scale > 2.0 or common_pts < 200 :\n",
    "                                if scale > 1.75 or common_pts < 200 :\n",
    "                                        # print(scale, common_pts, best_inliers)\n",
    "                                        # print(\"INSERTING KEYFRAME\")\n",
    "                                        no_of_triangulated = self.triangulate_new_ref_points(framepair)\n",
    "                                        if no_of_triangulated < 50:\n",
    "                                                # print(\"BAD TRIANGULATION \", no_of_triangulated)\n",
    "                                                return \n",
    "                                        framepair.frame1.kps_index = self.ref_kps_index[:, 0]\n",
    "                                        framepair.frame2.kps_index = self.ref_kps_index[:, 1]\n",
    "\n",
    "                                        # scale = self.get_local_scale(framepair)     \n",
    "                                        # print(\"LOCAL SCALE : \", scale)                            \n",
    "                                        to_update = True\n",
    "                                        # framepair.pose.t *= scale\n",
    "                                        # self.good_points_3D *= scale\n",
    "\n",
    "                                framepair.frame2.pose._pose = framepair.frame1.pose._pose @ framepair.pose._pose.copy()\n",
    "\n",
    "                                self.pose_ctr += 1\n",
    "                                self.global_poses[self.pose_ctr] = framepair.frame2.pose._pose\n",
    "                                self.get_point_in_other_image(framepair, to_update)\n",
    "\n",
    "                                # print(\"Current car pos : \", framepair.frame2.pose.t.T * self.global_scale)\n",
    "\n",
    "\n",
    "                                if to_update:\n",
    "                                        # print(\"--------------------- UPDATING REFERENCE FRAME TO %s with \"%(framepair.frame2.filename), framepair.frame2.pose.t.T, common_pts)\n",
    "                                        self.update_frames_data(framepair)\n",
    "                        else:\n",
    "                                framepair.frame2.pose._pose = framepair.frame1.pose._pose.copy()\n",
    "\n",
    "                                # cv2.waitKey(0)\n",
    "                                # cv2.destroyAllWindows()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11394,
     "status": "ok",
     "timestamp": 1615802163263,
     "user": {
      "displayName": "SHRUTHEESH R",
      "photoUrl": "",
      "userId": "00894520623679044885"
     },
     "user_tz": -330
    },
    "id": "94Xq9JWiXSlP",
    "outputId": "9143f904-f8d8-4c92-8ecf-38220dcf13cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "[[-0.95625781 -0.79484716  6.37870119]]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "idx = 0\n",
    "\n",
    "numpyseed = 4123\n",
    "midpoints = [(220, 327), (234, 308), (249, 299), (214, 327), (221, 307), (230, 312), (209, 309), (229, 299), (225, 290)]\n",
    "H = np.asarray([[9.857253690556300, 11.420517249932578, 225.120435603151577],[5.517731384524304, 1.254203539695659, 3254.912664208281967],[0.031589485917738, 0.002401109962928, 1.000000000000000]])\n",
    "\n",
    "cam_intr = np.asarray([[332.9648157406122, 0.0, 310.8472797033171], [0.0, 444.0950902369522, 252.76060777256825], [0.0, 0.0, 1.0]])\n",
    "\n",
    "\n",
    "weights_path = 'model_final_final_iisc_idd_16kweights.pth'\n",
    "auto_park_obj = auto_park_vision(weights_path)\n",
    "points_ls = [[620,200,1],[620,-200,1],[1120,-200,1],[1120,200,1]]\n",
    "points_2d_ls = world_2d(points_ls) #[967,427],[295,438],[438,309],[817,300]\n",
    "\n",
    "\n",
    "for seq_no in range(1, 2):\n",
    "    print(seq_no + 5)\n",
    "    np.random.seed(numpyseed)\n",
    "    images_directory = \"all_sequences/%02d\"%(seq_no)\n",
    "    vo = VisualOdometry(cam_intr, H)\n",
    "    start_no = 0\n",
    "    for index, file_path in enumerate(sorted(glob.glob(images_directory + \"/left*\"))[start_no::5]):\n",
    "        if index ==1 :\n",
    "            continue\n",
    "        frame = cv2.imread(file_path)\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frame = cv2.resize(frame, (640,480), interpolation = cv2.INTER_LANCZOS4)\n",
    "        frame_pil = Image.fromarray(frame)\n",
    "        midpoint_2D = midpoints[seq_no]\n",
    "\n",
    "        seg_img = auto_park_obj.forward_pass(frame_pil,img_path=None)\n",
    "\n",
    "        vo.process_frame(frame, seg_img, midpoint_2D, index,  file_path)\n",
    "    print(vo.cur_data.pose.t.T * vo.global_scale)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1339,
     "status": "ok",
     "timestamp": 1615802168990,
     "user": {
      "displayName": "SHRUTHEESH R",
      "photoUrl": "",
      "userId": "00894520623679044885"
     },
     "user_tz": -330
    },
    "id": "-b7RVl8kYD0I",
    "outputId": "511118a0-4aee-44bc-8035-12def5ea8c06"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m461Gzc364sJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 874320,
     "status": "ok",
     "timestamp": 1614675129640,
     "user": {
      "displayName": "SHRUTHEESH R",
      "photoUrl": "",
      "userId": "00894520623679044885"
     },
     "user_tz": -330
    },
    "id": "ZwOgvDcFjP4W",
    "outputId": "c52103d2-5847-4077-c6fd-d92559526443"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qI1T8zF6iboE"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyN6m9FiOzQzNZbdeS4jP2dM",
   "collapsed_sections": [],
   "mount_file_id": "1Na5N8WvNg897G_ZbB411on6d6U4DCG4N",
   "name": "Homography_img.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
